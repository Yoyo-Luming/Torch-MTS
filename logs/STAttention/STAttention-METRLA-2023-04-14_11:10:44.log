METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 1)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 1)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 1)

--------- STAttention ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        10,
        50
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 20,
    "use_cl": false,
    "cl_step_size": 2500,
    "model_args": {
        "num_nodes": 207,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 12,
        "tod_embedding_dim": 12,
        "dow_embedding_dim": 12,
        "adaptive_embedding_dim": 60,
        "feed_forward_dim": 128,
        "num_heads": 4,
        "num_layers": 3,
        "dropout": 0.1
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
STAttention                              --                        --
├─ModuleList: 1-1                        --                        --
│    └─ModuleList: 2-1                   --                        --
│    └─ModuleList: 2-2                   --                        --
│    └─ModuleList: 2-3                   --                        --
├─ModuleList: 1-2                        --                        --
│    └─ModuleList: 2-4                   --                        --
│    └─ModuleList: 2-5                   --                        --
│    └─ModuleList: 2-6                   --                        --
├─Linear: 1-3                            [64, 12, 207, 12]         24
├─Embedding: 1-4                         [64, 12, 207, 12]         3,456
├─Embedding: 1-5                         [64, 12, 207, 12]         84
├─ModuleList: 1-1                        --                        --
│    └─ModuleList: 2-1                   --                        --
│    │    └─LayerNorm: 3-1               [64, 12, 207, 96]         192
│    │    └─Sequential: 3-2              [64, 12, 207, 96]         24,800
│    │    └─LayerNorm: 3-3               [64, 12, 207, 96]         192
│    └─ModuleList: 2-2                   --                        --
│    │    └─LayerNorm: 3-4               [64, 12, 207, 96]         192
│    │    └─Sequential: 3-5              [64, 12, 207, 96]         24,800
│    │    └─LayerNorm: 3-6               [64, 12, 207, 96]         192
│    └─ModuleList: 2-3                   --                        --
│    │    └─LayerNorm: 3-7               [64, 12, 207, 96]         192
│    │    └─Sequential: 3-8              [64, 12, 207, 96]         24,800
│    │    └─LayerNorm: 3-9               [64, 12, 207, 96]         192
├─ModuleList: 1-2                        --                        --
│    └─ModuleList: 2-4                   --                        --
│    │    └─LayerNorm: 3-10              [64, 12, 207, 96]         192
│    │    └─Sequential: 3-11             [64, 12, 207, 96]         24,800
│    │    └─LayerNorm: 3-12              [64, 12, 207, 96]         192
│    └─ModuleList: 2-5                   --                        --
│    │    └─LayerNorm: 3-13              [64, 12, 207, 96]         192
│    │    └─Sequential: 3-14             [64, 12, 207, 96]         24,800
│    │    └─LayerNorm: 3-15              [64, 12, 207, 96]         192
│    └─ModuleList: 2-6                   --                        --
│    │    └─LayerNorm: 3-16              [64, 12, 207, 96]         192
│    │    └─Sequential: 3-17             [64, 12, 207, 96]         24,800
│    │    └─LayerNorm: 3-18              [64, 12, 207, 96]         192
├─Linear: 1-6                            [64, 96, 207, 12]         156
├─Linear: 1-7                            [64, 12, 207, 1]          97
==========================================================================================
Total params: 154,921
Trainable params: 154,921
Non-trainable params: 0
Total mult-adds (M): 9.91
==========================================================================================
Input size (MB): 1.91
Forward/backward pass size (MB): 3343.58
Params size (MB): 0.62
Estimated Total Size (MB): 3346.11
==========================================================================================

Loss: MaskedMAELoss

2023-04-14 11:11:25.842122 Epoch 1  	Train Loss = 4.99084 Val Loss = 3.63935
2023-04-14 11:12:01.251560 Epoch 2  	Train Loss = 3.68608 Val Loss = 3.36856
2023-04-14 11:12:36.893407 Epoch 3  	Train Loss = 3.46499 Val Loss = 3.31635
2023-04-14 11:13:12.610380 Epoch 4  	Train Loss = 3.37130 Val Loss = 3.20629
2023-04-14 11:13:48.314949 Epoch 5  	Train Loss = 3.28149 Val Loss = 3.11649
2023-04-14 11:14:24.350967 Epoch 6  	Train Loss = 3.20504 Val Loss = 3.11791
2023-04-14 11:15:00.593130 Epoch 7  	Train Loss = 3.15407 Val Loss = 3.06342
2023-04-14 11:15:36.598711 Epoch 8  	Train Loss = 3.10993 Val Loss = 3.04119
2023-04-14 11:16:12.426474 Epoch 9  	Train Loss = 3.07636 Val Loss = 3.02548
2023-04-14 11:16:48.453903 Epoch 10  	Train Loss = 3.04797 Val Loss = 3.04549
2023-04-14 11:17:25.254441 Epoch 11  	Train Loss = 2.98900 Val Loss = 2.97681
2023-04-14 11:18:02.546028 Epoch 12  	Train Loss = 2.97847 Val Loss = 2.97887
2023-04-14 11:18:39.482344 Epoch 13  	Train Loss = 2.97463 Val Loss = 2.98190
2023-04-14 11:19:16.221730 Epoch 14  	Train Loss = 2.97118 Val Loss = 2.97972
2023-04-14 11:19:52.897630 Epoch 15  	Train Loss = 2.96780 Val Loss = 2.98384
2023-04-14 11:20:29.160007 Epoch 16  	Train Loss = 2.96407 Val Loss = 2.98308
2023-04-14 11:21:05.075315 Epoch 17  	Train Loss = 2.96225 Val Loss = 2.97868
2023-04-14 11:21:40.835030 Epoch 18  	Train Loss = 2.95957 Val Loss = 2.97485
2023-04-14 11:22:16.555738 Epoch 19  	Train Loss = 2.95700 Val Loss = 2.97537
2023-04-14 11:22:52.553695 Epoch 20  	Train Loss = 2.95386 Val Loss = 2.97892
2023-04-14 11:23:28.387083 Epoch 21  	Train Loss = 2.95115 Val Loss = 2.98619
2023-04-14 11:24:04.250238 Epoch 22  	Train Loss = 2.94990 Val Loss = 2.97358
2023-04-14 11:24:40.329333 Epoch 23  	Train Loss = 2.94642 Val Loss = 2.96666
2023-04-14 11:25:16.052552 Epoch 24  	Train Loss = 2.94462 Val Loss = 2.96331
2023-04-14 11:25:51.920883 Epoch 25  	Train Loss = 2.94297 Val Loss = 2.97918
2023-04-14 11:26:27.997553 Epoch 26  	Train Loss = 2.94128 Val Loss = 2.97387
2023-04-14 11:27:04.607734 Epoch 27  	Train Loss = 2.93754 Val Loss = 2.97742
2023-04-14 11:27:41.490906 Epoch 28  	Train Loss = 2.93694 Val Loss = 2.96981
2023-04-14 11:28:18.399126 Epoch 29  	Train Loss = 2.93457 Val Loss = 2.98701
2023-04-14 11:28:55.211001 Epoch 30  	Train Loss = 2.93421 Val Loss = 2.96417
2023-04-14 11:29:31.780727 Epoch 31  	Train Loss = 2.93053 Val Loss = 2.97423
2023-04-14 11:30:08.194909 Epoch 32  	Train Loss = 2.92997 Val Loss = 2.96045
2023-04-14 11:30:44.658211 Epoch 33  	Train Loss = 2.92828 Val Loss = 2.97714
2023-04-14 11:31:21.251777 Epoch 34  	Train Loss = 2.92718 Val Loss = 2.96915
2023-04-14 11:31:58.254234 Epoch 35  	Train Loss = 2.92481 Val Loss = 2.98139
2023-04-14 11:32:35.368526 Epoch 36  	Train Loss = 2.92467 Val Loss = 2.97312
2023-04-14 11:33:12.363275 Epoch 37  	Train Loss = 2.92201 Val Loss = 2.96364
2023-04-14 11:33:49.384589 Epoch 38  	Train Loss = 2.92135 Val Loss = 2.98208
2023-04-14 11:34:26.108691 Epoch 39  	Train Loss = 2.91910 Val Loss = 2.99015
2023-04-14 11:35:02.315157 Epoch 40  	Train Loss = 2.91808 Val Loss = 2.96492
2023-04-14 11:35:38.049498 Epoch 41  	Train Loss = 2.91647 Val Loss = 2.96906
2023-04-14 11:36:13.776037 Epoch 42  	Train Loss = 2.91511 Val Loss = 2.97711
2023-04-14 11:36:49.478939 Epoch 43  	Train Loss = 2.91471 Val Loss = 2.98317
2023-04-14 11:37:25.215756 Epoch 44  	Train Loss = 2.91345 Val Loss = 2.97012
2023-04-14 11:38:00.902515 Epoch 45  	Train Loss = 2.91150 Val Loss = 2.96158
2023-04-14 11:38:36.584013 Epoch 46  	Train Loss = 2.91086 Val Loss = 2.97764
2023-04-14 11:39:12.524786 Epoch 47  	Train Loss = 2.90911 Val Loss = 2.96632
2023-04-14 11:39:48.402846 Epoch 48  	Train Loss = 2.90800 Val Loss = 2.96335
2023-04-14 11:40:24.715131 Epoch 49  	Train Loss = 2.90659 Val Loss = 2.96115
2023-04-14 11:41:00.693387 Epoch 50  	Train Loss = 2.90638 Val Loss = 2.96580
2023-04-14 11:41:36.819327 Epoch 51  	Train Loss = 2.89550 Val Loss = 2.96515
2023-04-14 11:42:13.099312 Epoch 52  	Train Loss = 2.89321 Val Loss = 2.96725
Early stopping at epoch: 52
Best at epoch 32:
Train Loss = 2.92997
Train RMSE = 5.89846, MAE = 2.89233, MAPE = 7.86656
Val Loss = 2.96045
Val RMSE = 6.29305, MAE = 3.01694, MAPE = 8.64810
--------- Test ---------
All Steps RMSE = 6.56446, MAE = 3.18027, MAPE = 9.27373
Step 1 RMSE = 4.53918, MAE = 2.46301, MAPE = 6.29492
Step 2 RMSE = 5.18809, MAE = 2.68023, MAPE = 7.10078
Step 3 RMSE = 5.64083, MAE = 2.84626, MAPE = 7.75690
Step 4 RMSE = 5.99670, MAE = 2.99263, MAPE = 8.37701
Step 5 RMSE = 6.29442, MAE = 3.11683, MAPE = 8.93989
Step 6 RMSE = 6.57307, MAE = 3.22582, MAPE = 9.45572
Step 7 RMSE = 6.83648, MAE = 3.31706, MAPE = 9.89072
Step 8 RMSE = 7.04687, MAE = 3.38722, MAPE = 10.21821
Step 9 RMSE = 7.22354, MAE = 3.44639, MAPE = 10.47343
Step 10 RMSE = 7.38090, MAE = 3.50283, MAPE = 10.70114
Step 11 RMSE = 7.53377, MAE = 3.56087, MAPE = 10.92514
Step 12 RMSE = 7.69238, MAE = 3.62416, MAPE = 11.15124
Inference time: 3.12 s
